{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# **Classical Implementation**"],"metadata":{"id":"-0hz35R92FSk"}},{"cell_type":"markdown","source":["Constants"],"metadata":{"id":"EVI8L4ON2kx5"}},{"cell_type":"code","source":["\"\"\"Constants in common between the examples provided,\n","i.e., regardless of the framework used (whether PyTorch or\n","tf.keras)\"\"\"\n","\n","BATCH_SIZE = 128\n","\n","DROPOUT = 0.5\n","\n","IMAGE_DIM = 28\n","\n","KERNEL_SIZE_CONV = 3\n","KERNEL_SIZE_MAX_POOL = 2\n","\n","NUM_CLASSES = 10\n","NUM_EPOCHS = 30\n","\n","OUT_CHANNEL_CONV1 = 32\n","OUT_CHANNEL_CONV2 = 64"],"metadata":{"id":"Typ0SkJS4Icj","executionInfo":{"status":"ok","timestamp":1734275941842,"user_tz":-300,"elapsed":351,"user":{"displayName":"Huzaifah Tariq Ahmed","userId":"08544110060404195831"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","from torch.utils.data import DataLoader\n","from torchvision import transforms\n","\n","inputs_shape = (1, IMAGE_DIM, IMAGE_DIM)\n","\n","# Load MNIST dataset\n","transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.1307,), (0.3081,))\n","])\n","\n","train_dataset = torchvision.datasets.MNIST(\n","    root='./data', train=True, download=True, transform=transform)\n","test_dataset = torchvision.datasets.MNIST(\n","    root='./data', train=False, download=True, transform=transform)\n","\n","train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n","\n","\n","class ConvNet(nn.Module):\n","    \"\"\"\n","    Convolutional Neural Network model for image classification using classical ReLU activation.\n","\n","    Args:\n","        modified: bool\n","            Whether to use the modified version of the QReLU or m-QReLU (default: False).\n","\n","    Attributes:\n","        conv1: nn.Conv2d\n","            First convolutional layer.\n","        relu1: nn.ReLU\n","            First ReLU activation.\n","        pool1: nn.MaxPool2d\n","            First max pooling layer.\n","        conv2: nn.Conv2d\n","            Second convolutional layer.\n","        relu2: nn.ReLU\n","            Second ReLU activation.\n","        pool2: nn.MaxPool2d\n","            Second max pooling layer.\n","        flatten: nn.Flatten\n","            Flatten layer.\n","        dropout: nn.Dropout\n","            Dropout layer.\n","        fc: nn.Linear\n","            Fully connected layer.\n","    \"\"\"\n","\n","    def __init__(self):\n","        super(ConvNet, self).__init__()\n","        self.conv1 = nn.Conv2d(1, OUT_CHANNEL_CONV1, kernel_size=KERNEL_SIZE_CONV)\n","        self.relu1 = nn.ReLU()  # Using classical ReLU instead of QuantumReLU\n","        self.pool1 = nn.MaxPool2d(kernel_size=2)\n","        self.conv2 = nn.Conv2d(OUT_CHANNEL_CONV1, OUT_CHANNEL_CONV2, kernel_size=KERNEL_SIZE_CONV)\n","        self.relu2 = nn.ReLU()  # Using classical ReLU instead of QuantumReLU\n","        self.pool2 = nn.MaxPool2d(kernel_size=KERNEL_SIZE_MAX_POOL)\n","        self.flatten = nn.Flatten()\n","        self.dropout = nn.Dropout(DROPOUT)\n","        self.fc = nn.Linear(OUT_CHANNEL_CONV2 * 5 * 5, NUM_CLASSES)\n","\n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\n","        \"\"\"\n","        Forward pass through the network.\n","\n","        Args:\n","            x: torch.Tensor\n","                The Input tensor.\n","\n","        Returns:\n","            Output tensor (torch.Tensor).\n","        \"\"\"\n","        x = self.pool1(self.relu1(self.conv1(x)))\n","        x = self.pool2(self.relu2(self.conv2(x)))\n","        x = self.flatten(x)\n","        x = self.dropout(x)\n","        x = self.fc(x)\n","        return x\n","\n","\n","def train(\n","        model: nn.Module,\n","        train_loader: DataLoader,\n","        optimizer: optim.Optimizer,\n","        criterion: nn.Module,\n","        epochs: int = NUM_EPOCHS\n",") -> None:\n","    \"\"\"\n","    Train the model.\n","\n","    Args:\n","        model: nn.Module\n","            The neural network model to be trained.\n","        train_loader: DataLoader\n","            Data loader for training data.\n","        optimizer: optim.Optimizer\n","            Optimizer for training.\n","        criterion: nn.Module\n","            Loss function.\n","        epochs: int\n","            Number of epochs for training (default: NUM_EPOCHS).\n","    \"\"\"\n","    for epoch in range(epochs):\n","        model.train()\n","        running_loss = 0.0\n","        for inputs, labels in train_loader:\n","            optimizer.zero_grad()\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","            running_loss += loss.item() * inputs.size(0)\n","        epoch_loss = running_loss / len(train_loader.dataset)\n","        print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {epoch_loss:.4f}\")\n","\n","\n","def test(\n","        model: nn.Module,\n","        test_loader: DataLoader\n",") -> None:\n","    \"\"\"\n","    Evaluate the trained model on test data.\n","\n","    Args:\n","        model: nn.Module\n","            The trained model to be evaluated.\n","        test_loader: DataLoader\n","            Data loader for test data.\n","    \"\"\"\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for inputs, labels in test_loader:\n","            outputs = model(inputs)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","    print(f\"Accuracy: {100 * correct / total:.2f}%\")\n","\n","\n","# Initialize the model\n","model = ConvNet()\n","print(model)\n","\n","# Define criterion and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters())\n","\n","# Train and test the modelm\n","train(model, train_loader, optimizer, criterion)\n","test(model, test_loader)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gmF-kF5D2prc","executionInfo":{"status":"ok","timestamp":1734277632077,"user_tz":-300,"elapsed":1687519,"user":{"displayName":"Huzaifah Tariq Ahmed","userId":"08544110060404195831"}},"outputId":"8ff3e756-9fd6-4f45-8c16-11b33c86fcfe"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["ConvNet(\n","  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n","  (relu1): ReLU()\n","  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n","  (relu2): ReLU()\n","  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (flatten): Flatten(start_dim=1, end_dim=-1)\n","  (dropout): Dropout(p=0.5, inplace=False)\n","  (fc): Linear(in_features=1600, out_features=10, bias=True)\n",")\n","Epoch [1/30], Loss: 0.2351\n","Epoch [2/30], Loss: 0.0833\n","Epoch [3/30], Loss: 0.0656\n","Epoch [4/30], Loss: 0.0548\n","Epoch [5/30], Loss: 0.0493\n","Epoch [6/30], Loss: 0.0447\n","Epoch [7/30], Loss: 0.0427\n","Epoch [8/30], Loss: 0.0388\n","Epoch [9/30], Loss: 0.0369\n","Epoch [10/30], Loss: 0.0350\n","Epoch [11/30], Loss: 0.0330\n","Epoch [12/30], Loss: 0.0326\n","Epoch [13/30], Loss: 0.0286\n","Epoch [14/30], Loss: 0.0293\n","Epoch [15/30], Loss: 0.0261\n","Epoch [16/30], Loss: 0.0272\n","Epoch [17/30], Loss: 0.0253\n","Epoch [18/30], Loss: 0.0237\n","Epoch [19/30], Loss: 0.0255\n","Epoch [20/30], Loss: 0.0238\n","Epoch [21/30], Loss: 0.0245\n","Epoch [22/30], Loss: 0.0209\n","Epoch [23/30], Loss: 0.0221\n","Epoch [24/30], Loss: 0.0203\n","Epoch [25/30], Loss: 0.0207\n","Epoch [26/30], Loss: 0.0214\n","Epoch [27/30], Loss: 0.0189\n","Epoch [28/30], Loss: 0.0178\n","Epoch [29/30], Loss: 0.0183\n","Epoch [30/30], Loss: 0.0185\n","Accuracy: 99.32%\n"]}]},{"cell_type":"markdown","source":["# **Quantum Implementation**"],"metadata":{"id":"F7VEFFv22SnM"}},{"cell_type":"markdown","source":["Constants"],"metadata":{"id":"s4ZP3Raf9CMX"}},{"cell_type":"code","source":["\"\"\"Constants in common between the examples provided,\n","i.e., regardless of the framework used (whether PyTorch or\n","tf.keras)\"\"\"\n","\n","BATCH_SIZE = 128\n","\n","DROPOUT = 0.5\n","\n","IMAGE_DIM = 28\n","\n","KERNEL_SIZE_CONV = 3\n","KERNEL_SIZE_MAX_POOL = 2\n","\n","NUM_CLASSES = 10\n","NUM_EPOCHS = 2\n","\n","OUT_CHANNEL_CONV1 = 32\n","OUT_CHANNEL_CONV2 = 64"],"metadata":{"id":"kvN7Oi6E8jRM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Src.Constants"],"metadata":{"id":"MpCgCDv79EEs"}},{"cell_type":"code","source":["\"\"\"\n","This file contains constants leveraged across the two quantum activation functions\n","QReLU and m-QReLU regardless of the framework (TensorFlow or Keras or PyTorch)\n","of their implementation.\n","\"\"\"\n","\n","import torch\n","\n","FIRST_COEFFICIENT = 0.01\n","SECOND_COEFFICIENT_QRELU = 2\n","SECOND_COEFFICIENT_M_QRELU = 1\n","\n","FIRST_COEFFICIENT_PYTORCH = torch.tensor(FIRST_COEFFICIENT)\n","SECOND_COEFFICIENT_QRELU_PYTORCH = torch.tensor(SECOND_COEFFICIENT_QRELU)\n","SECOND_COEFFICIENT_M_QRELU_PYTORCH = torch.tensor(SECOND_COEFFICIENT_M_QRELU)\n","\n","M_QRELU_NAME = \"modified_quantum_relu\"\n","QRELU_NAME = \"quantum_relu\"\n","\n","USE_M_QRELU = False"],"metadata":{"id":"kuE-ndhj8u5E"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["pytorch.quantum activations"],"metadata":{"id":"BjkLt-Lr9QER"}},{"cell_type":"code","source":["\"\"\"Additional utility for Deep Learning models in PyTorch\"\"\"\n","\n","# The Quantum ReLU (QReLU) and the modified QReLU (m-QReLU) as custom activation functions in\n","# PyTorch\n","\n","# Author: Luca Parisi <luca.parisi@ieee.org>\n","\n","import torch\n","import torch.nn as nn\n","# from src.constants import (FIRST_COEFFICIENT_PYTORCH, M_QRELU_NAME, QRELU_NAME,\n","#                            SECOND_COEFFICIENT_M_QRELU_PYTORCH,\n","#                            SECOND_COEFFICIENT_QRELU_PYTORCH, USE_M_QRELU)\n","\n","\n","class QuantumReLU(nn.Module):  # pragma: no cover\n","    \"\"\"\n","    A class defining the QuantumReLU activation function in PyTorch.\n","    \"\"\"\n","\n","    def __init__(self, modified: bool = USE_M_QRELU) -> None:\n","        \"\"\"\n","        Initialise the QuantumReLU activation function.\n","\n","        Args:\n","            modified: bool\n","                    Whether using the modified version of the QReLU or m-QReLU (no/False by default,\n","                    i.e., using the QReLU by default).\n","        \"\"\"\n","\n","        self.modified = modified\n","        self._name = M_QRELU_NAME if modified else QRELU_NAME\n","        super().__init__()\n","\n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\n","        \"\"\"\n","        Call the QuantumReLU activation function.\n","\n","        Args:\n","            x: torch.Tensor\n","                The input tensor.\n","\n","        Returns:\n","                The output tensor (torch.Tensor) from the QuantumReLU activation function.\n","        \"\"\"\n","        return torch_quantum_relu(x=x, modified=self.modified)\n","\n","\n","def torch_quantum_relu(x: torch.Tensor, modified: bool = USE_M_QRELU) -> torch.Tensor:\n","    \"\"\"\n","    Apply the QReLU activation function or its modified version (m-QReLU) to transform inputs accordingly.\n","\n","    Args:\n","        x: torch.Tensor\n","            The input tensor to be transformed via the m-QReLU activation function.\n","        modified: bool\n","            Whether using the modified version of the QReLU or m-QReLU (no/False by default, i.e.,\n","            using the QReLU by default).\n","\n","    Returns:\n","            The transformed x (torch.Tensor) via the QReLU or m-QReLU.\n","    \"\"\"\n","    second_coefficient = SECOND_COEFFICIENT_M_QRELU_PYTORCH if modified else SECOND_COEFFICIENT_QRELU_PYTORCH\n","    return torch.where(\n","            x <= 0,\n","            FIRST_COEFFICIENT_PYTORCH * x - second_coefficient * x,\n","            x,\n","    )"],"metadata":{"id":"0I5aY3_e9KpB"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xA7y6h_Z7wgu","outputId":"dee529d6-f4f9-4c43-b5ac-c6e50b20911e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 403: Forbidden\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9.91M/9.91M [00:00<00:00, 17.5MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 403: Forbidden\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28.9k/28.9k [00:00<00:00, 488kB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 403: Forbidden\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1.65M/1.65M [00:00<00:00, 4.41MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 403: Forbidden\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4.54k/4.54k [00:00<00:00, 2.97MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","\n","ConvNet(\n","  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n","  (relu1): QuantumReLU()\n","  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n","  (relu2): QuantumReLU()\n","  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (flatten): Flatten(start_dim=1, end_dim=-1)\n","  (dropout): Dropout(p=0.5, inplace=False)\n","  (fc): Linear(in_features=1600, out_features=10, bias=True)\n",")\n","Epoch [1/2], Loss: 0.3163\n","Epoch [2/2], Loss: 0.1237\n","Accuracy: 98.22%\n"]}],"source":["\"\"\"\n","Example of a simple MNIST image classifier using the QReLU or m-QReLU activation function in its two\n","convolutional layers.\n","\n","Adapted from https://keras.io/examples/vision/mnist_convnet/\n","\"\"\"\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","# from constants import (BATCH_SIZE, DROPOUT, IMAGE_DIM, KERNEL_SIZE_CONV,\n","#                        KERNEL_SIZE_MAX_POOL, NUM_CLASSES, NUM_EPOCHS,\n","#                        OUT_CHANNEL_CONV1, OUT_CHANNEL_CONV2)\n","# from src.constants import USE_M_QRELU\n","# from src.pytorch.quantum_activations import QuantumReLU\n","from torch.utils.data import DataLoader\n","from torchvision import transforms\n","\n","inputs_shape = (1, IMAGE_DIM, IMAGE_DIM)\n","\n","# Load MNIST dataset\n","transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.1307,), (0.3081,))\n","])\n","\n","train_dataset = torchvision.datasets.MNIST(\n","    root='./data', train=True, download=True, transform=transform)\n","test_dataset = torchvision.datasets.MNIST(\n","    root='./data', train=False, download=True, transform=transform)\n","\n","train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n","\n","\n","class ConvNet(nn.Module):\n","    \"\"\"\n","    Convolutional Neural Network model for image classification.\n","\n","    Args:\n","        modified: bool\n","            Whether to use the modified version of the\n","            QReLU or m-QReLU (default: False).\n","\n","    Attributes:\n","        conv1: nn.Conv2d\n","            First convolutional layer.\n","        relu1: QuantumReLU\n","            First Quantum ReLU activation.\n","        pool1: nn.MaxPool2d\n","            First max pooling layer.\n","        conv2: nn.Conv2d\n","            Second convolutional layer.\n","        relu2: QuantumReLU\n","            Second Quantum ReLU activation.\n","        pool2: nn.MaxPool2d\n","            Second max pooling layer.\n","        flatten: nn.Flatten\n","            Flatten layer.\n","        dropout: nn.Dropout\n","            Dropout layer.\n","        fc: nn.Linear\n","            Fully connected layer.\n","    \"\"\"\n","\n","    def __init__(self, modified=False):\n","        super(ConvNet, self).__init__()\n","        self.conv1 = nn.Conv2d(1, OUT_CHANNEL_CONV1,\n","                               kernel_size=KERNEL_SIZE_CONV)\n","        self.relu1 = QuantumReLU(modified=modified)\n","        self.pool1 = nn.MaxPool2d(kernel_size=2)\n","        self.conv2 = nn.Conv2d(\n","            OUT_CHANNEL_CONV1, OUT_CHANNEL_CONV2, kernel_size=KERNEL_SIZE_CONV)\n","        self.relu2 = QuantumReLU(modified=modified)\n","        self.pool2 = nn.MaxPool2d(kernel_size=KERNEL_SIZE_MAX_POOL)\n","        self.flatten = nn.Flatten()\n","        self.dropout = nn.Dropout(DROPOUT)\n","        self.fc = nn.Linear(OUT_CHANNEL_CONV2 * 5 * 5, NUM_CLASSES)\n","\n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\n","        \"\"\"\n","        Forward pass through the network.\n","\n","        Args:\n","            x: torch.Tensor\n","                The Input tensor.\n","\n","        Returns:\n","            Output tensor (torch.Tensor).\n","        \"\"\"\n","        x = self.pool1(self.relu1(self.conv1(x)))\n","        x = self.pool2(self.relu2(self.conv2(x)))\n","        x = self.flatten(x)\n","        x = self.dropout(x)\n","        x = self.fc(x)\n","        return x\n","\n","\n","def train(\n","        model: nn.Module,\n","        train_loader: DataLoader,\n","        optimizer: optim.Optimizer,\n","        criterion: nn.Module,\n","        epochs: int = NUM_EPOCHS\n",") -> None:\n","    \"\"\"\n","    Train the model.\n","\n","    Args:\n","        model: nn.Module\n","            The neural network model to be trained.\n","        train_loader: DataLoader\n","            Data loader for training data.\n","        optimizer: optim.Optimizer\n","            Optimizer for training.\n","        criterion: nn.Module\n","            Loss function.\n","        epochs: int\n","            Number of epochs for training (default: NUM_EPOCHS).\n","    \"\"\"\n","    for epoch in range(epochs):\n","        model.train()\n","        running_loss = 0.0\n","        for inputs, labels in train_loader:\n","            optimizer.zero_grad()\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","            running_loss += loss.item() * inputs.size(0)\n","        epoch_loss = running_loss / len(train_loader.dataset)\n","        print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {epoch_loss:.4f}\")\n","\n","\n","def test(\n","        model: nn.Module,\n","        test_loader: DataLoader\n",") -> None:\n","    \"\"\"\n","    Evaluate the trained model on test data.\n","\n","    Args:\n","        model: nn.Module\n","            The trained model to be evaluated.\n","        test_loader: DataLoader\n","            Data loader for test data.\n","    \"\"\"\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for inputs, labels in test_loader:\n","            outputs = model(inputs)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","    print(f\"Accuracy: {100 * correct / total:.2f}%\")\n","\n","\n","model = ConvNet(modified=USE_M_QRELU)\n","print(model)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters())\n","\n","train(model, train_loader, optimizer, criterion)\n","test(model, test_loader)\n"]}]}